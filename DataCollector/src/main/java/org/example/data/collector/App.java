/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package org.example.data.collector;

import org.apache.kafka.common.PartitionInfo;

import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.stream.Collectors;

public class App {

    public static void main(String[] args) {
        MyKafkaConsumer consumer = new MyKafkaConsumer();
        List<String> topics = (List<String>) consumer.listTopics().keySet().stream().filter(o -> !o.toString().startsWith("_")).collect(Collectors.toList());
        System.out.println(topics);
        consumer.close();
        ElasticSearchWriter elasticSearchWriter = new ElasticSearchWriter(topics);
        elasticSearchWriter.createIndexes();

        ExecutorService executorService = Executors.newFixedThreadPool(topics.size());
        for (String topic : topics) {
            DataProcessor dataProcessor = new DataProcessor(elasticSearchWriter);
            final MyKafkaConsumer specificTopicConsumer = new MyKafkaConsumer<>(dataProcessor);
            specificTopicConsumer.subscribe(List.of(topic));
            executorService.submit(() -> specificTopicConsumer.startConsume());
        }
        System.out.println("BGBG");
    }
}
